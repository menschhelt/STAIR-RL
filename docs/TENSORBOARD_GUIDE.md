# TensorBoard ì‚¬ìš© ê°€ì´ë“œ

STAIR-RL í•™ìŠµ ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê¸° ìœ„í•œ TensorBoard ì‚¬ìš© ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í•™ìŠµ ì‹œì‘
```bash
# Phase 1: CQL-SAC í•™ìŠµ (ì„ë² ë”© ìë™ ë¡œë“œ)
python scripts/run_training.py --phase 1 --steps 500000 --gpu 0

# ë˜ëŠ” Phase 2: PPO-CVaR í•™ìŠµ
python scripts/run_training.py --phase 2 --steps 100000 --gpu 0 \
  --pretrained checkpoints/phase1/cql_sac_final.pt
```

í•™ìŠµì´ ì‹œì‘ë˜ë©´ ì½˜ì†”ì— ë‹¤ìŒê³¼ ê°™ì€ ë©”ì‹œì§€ê°€ í‘œì‹œë©ë‹ˆë‹¤:
```
TensorBoard logging to: checkpoints/run_20250115_143022/phase1/tensorboard
  View with: tensorboard --logdir checkpoints/run_20250115_143022/phase1/tensorboard
```

### 2. TensorBoard ì‹¤í–‰

**ë°©ë²• 1: í—¬í¼ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš© (ê¶Œì¥)**
```bash
# ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ìë™ìœ¼ë¡œ ì°¾ì•„ì„œ ì‹¤í–‰
./scripts/launch_tensorboard.sh

# ë˜ëŠ” íŠ¹ì • ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ì§€ì •
./scripts/launch_tensorboard.sh checkpoints/run_20250115_143022
```

**ë°©ë²• 2: ì§ì ‘ ì‹¤í–‰**
```bash
# Phase 1ë§Œ ëª¨ë‹ˆí„°ë§
tensorboard --logdir checkpoints/run_20250115_143022/phase1/tensorboard \
  --port 6006 --bind_all

# Phase 1 + Phase 2 ë™ì‹œ ëª¨ë‹ˆí„°ë§
tensorboard --logdir_spec \
  phase1:checkpoints/run_20250115_143022/phase1/tensorboard,\
  phase2:checkpoints/run_20250115_143022/phase2/tensorboard \
  --port 6006 --bind_all
```

### 3. ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†

TensorBoardê°€ ì‹¤í–‰ë˜ë©´ ë‹¤ìŒ ì£¼ì†Œë¡œ ì ‘ì†:
- **ë¡œì»¬**: http://localhost:6006
- **ì›ê²© ì„œë²„**: http://<ì„œë²„IP>:6006

---

## ğŸ“Š ë¡œê¹…ë˜ëŠ” ë©”íŠ¸ë¦­

### Phase 1: CQL-SAC (Offline Pre-training)

#### Loss Metrics
- **Loss/Critic**: Critic ë„¤íŠ¸ì›Œí¬ ì†ì‹¤ (Q-value prediction error)
- **Loss/Actor**: Actor ë„¤íŠ¸ì›Œí¬ ì†ì‹¤ (policy gradient)
- **Loss/CQL**: Conservative Q-Learning ì •ê·œí™” ì†ì‹¤
- **Loss/Total**: ì „ì²´ ì†ì‹¤ (Critic + Actor + CQL)

#### SAC Metrics
- **SAC/Alpha**: SAC ì˜¨ë„ íŒŒë¼ë¯¸í„° (entropy coefficient)
- **Q-Value/Q1_Mean**: Q1 ë„¤íŠ¸ì›Œí¬ì˜ í‰ê·  Q-value
- **Q-Value/Q2_Mean**: Q2 ë„¤íŠ¸ì›Œí¬ì˜ í‰ê·  Q-value (twin Q-networks)

#### Gradient Metrics
- **GradNorm/Actor**: Actor ê·¸ë˜ë””ì–¸íŠ¸ norm (exploding/vanishing ì²´í¬)
- **GradNorm/Critic**: Critic ê·¸ë˜ë””ì–¸íŠ¸ norm

**í•´ì„:**
- `Loss/Critic`ê°€ ê°ì†Œí•˜ë©´ Q-value ì˜ˆì¸¡ì´ ê°œì„ ë¨
- `Loss/CQL`ì´ ì•ˆì •ì ì´ë©´ ë³´ìˆ˜ì  í•™ìŠµì´ ì˜ ë˜ëŠ” ê²ƒ
- `SAC/Alpha`ê°€ ìë™ìœ¼ë¡œ ì¡°ì •ë˜ë©´ì„œ exploration-exploitation ê· í˜• ìœ ì§€
- `GradNorm`ì´ ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ìœ¼ë©´ í•™ìŠµì´ ë¶ˆì•ˆì •

---

### Phase 2: PPO-CVaR (Online Fine-tuning)

#### Episode Metrics
- **Episode/Reward**: ì—í”¼ì†Œë“œë³„ ëˆ„ì  ë¦¬ì›Œë“œ (ìˆ˜ìµë¥ )
- **Episode/Steps**: ì—í”¼ì†Œë“œ ê¸¸ì´
- **Episode/TransactionCost**: ì—í”¼ì†Œë“œë³„ ì´ ê±°ë˜ ë¹„ìš©
- **Episode/Turnover**: ì—í”¼ì†Œë“œë³„ í¬íŠ¸í´ë¦¬ì˜¤ íšŒì „ìœ¨ (churning)

#### PPO Loss Metrics
- **Loss/Policy**: Policy ì†ì‹¤ (clipped surrogate objective)
- **Loss/Value**: Value ì†ì‹¤ (V-function prediction error)
- **Loss/Entropy**: Entropy ì†ì‹¤ (exploration bonus)
- **Loss/Total**: ì „ì²´ ì†ì‹¤

#### CVaR Metrics
- **CVaR/Value**: í˜„ì¬ CVaR ê°’ (95% confidence level)
- **CVaR/Lambda**: CVaR ì œì•½ì˜ ë¼ê·¸ë‘ì£¼ ìŠ¹ìˆ˜ (Î»)
- **CVaR/Violation**: CVaR ì œì•½ ìœ„ë°˜ ì •ë„

#### Policy Metrics
- **Policy/Entropy**: Policy entropy (ë†’ì„ìˆ˜ë¡ ë” íƒí—˜ì )
- **Policy/KL_Divergence**: KL divergence (policy ë³€í™”ëŸ‰)
- **Policy/ClipFraction**: PPO clipping ë¹„ìœ¨

**í•´ì„:**
- `Episode/Reward`ê°€ ì¦ê°€í•˜ë©´ ì „ëµì´ ê°œì„ ë¨
- `Episode/TransactionCost`ê°€ ë‚®ì•„ì§€ë©´ lazy tradingì´ ì˜ ì‘ë™
- `CVaR/Value`ê°€ ë‚®ì•„ì§€ë©´ ë¦¬ìŠ¤í¬ê°€ ê°ì†Œ (ëª©í‘œ: Îº=5% ì´í•˜)
- `CVaR/Lambda`ê°€ ì¦ê°€í•˜ë©´ CVaR ì œì•½ì´ ë” ê°•í•˜ê²Œ ì ìš©ë¨
- `Policy/KL_Divergence`ê°€ ë„ˆë¬´ í¬ë©´ í•™ìŠµì´ ë¶ˆì•ˆì • (PPO clip í•„ìš”)

---

## ğŸ” ëª¨ë‹ˆí„°ë§ íŒ

### 1. í•™ìŠµ ì§„í–‰ í™•ì¸

**ì •ìƒì ì¸ í•™ìŠµ íŒ¨í„´:**
- âœ… **Lossê°€ ê°ì†Œ**: Critic Loss, Actor Lossê°€ ì‹œê°„ì— ë”°ë¼ ê°ì†Œ
- âœ… **Q-value ì•ˆì •í™”**: Q1, Q2ê°€ ë°œì‚°í•˜ì§€ ì•Šê³  ì•ˆì •ì 
- âœ… **Reward ì¦ê°€**: Episode Rewardê°€ í‰ê· ì ìœ¼ë¡œ ì¦ê°€ ì¶”ì„¸
- âœ… **CVaR ê°ì†Œ**: CVaR ê°’ì´ ëª©í‘œì¹˜(5%) ì´í•˜ë¡œ ìœ ì§€

**ë¬¸ì œ ì‹ í˜¸:**
- âŒ **Loss í­ë°œ**: ì†ì‹¤ì´ ê¸‰ê²©íˆ ì¦ê°€ â†’ learning rate ê°ì†Œ í•„ìš”
- âŒ **Q-value ë°œì‚°**: Q-valueê°€ ê³„ì† ì¦ê°€ â†’ CQL ê°•í™” í•„ìš”
- âŒ **Reward ì •ì²´**: 100 episode ì´ìƒ ê°œì„  ì—†ìŒ â†’ exploration ê°•í™”
- âŒ **CVaR ìœ„ë°˜**: CVaRì´ ê³„ì† 5% ì´ˆê³¼ â†’ Î» ì¦ê°€ í•„ìš”

### 2. ë¹„êµ ì‹¤í—˜

ë³‘ë ¬ë¡œ ë‹¤ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì‹¤í—˜ì„ ì‹¤í–‰í•œ ê²½ìš°:
```bash
# GPU 0: LR 0.0001
CUDA_VISIBLE_DEVICES=0 python scripts/run_training.py --phase 1 --steps 500000 \
  --checkpoint-dir checkpoints/lr_0001 &

# GPU 1: LR 0.0003
CUDA_VISIBLE_DEVICES=1 python scripts/run_training.py --phase 1 --steps 500000 \
  --checkpoint-dir checkpoints/lr_0003 &

# ë‘ ì‹¤í—˜ì„ ë™ì‹œì— ëª¨ë‹ˆí„°ë§
tensorboard --logdir_spec \
  lr_0001:checkpoints/lr_0001/phase1/tensorboard,\
  lr_0003:checkpoints/lr_0003/phase1/tensorboard \
  --port 6006 --bind_all
```

TensorBoard ì¢Œì¸¡ í•˜ë‹¨ì˜ "Runs" ë©”ë‰´ì—ì„œ ì‹¤í—˜ë³„ë¡œ ìƒ‰ìƒì´ ë‹¤ë¥´ê²Œ í‘œì‹œë©ë‹ˆë‹¤.

### 3. ìŠ¤ë¬´ë”©(Smoothing) ì¡°ì •

TensorBoard ì¢Œì¸¡ ë©”ë‰´ì—ì„œ "Smoothing" ìŠ¬ë¼ì´ë”ë¥¼ ì¡°ì •í•˜ì—¬:
- **0.0**: ì›ë³¸ ë°ì´í„° (ë…¸ì´ì¦ˆ ë§ìŒ)
- **0.6** (ê¸°ë³¸ê°’): ì ë‹¹í•œ ìŠ¤ë¬´ë”©
- **0.9**: ê°•í•œ ìŠ¤ë¬´ë”© (íŠ¸ë Œë“œë§Œ ë³´ì„)

### 4. íŠ¹ì • ë©”íŠ¸ë¦­ ë‹¤ìš´ë¡œë“œ

TensorBoard ìš°ì¸¡ ìƒë‹¨ì˜ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ìœ¼ë¡œ CSV íŒŒì¼ ì €ì¥ ê°€ëŠ¥:
- ë…¼ë¬¸ ê·¸ë˜í”„ ì‘ì„±ìš©
- ì¶”ê°€ ë¶„ì„ìš©

---

## ğŸ¯ í•™ìŠµ ëª©í‘œ ë° ê¸°ì¤€

### Phase 1 (CQL-SAC) ì„±ê³µ ê¸°ì¤€
- âœ… `Loss/CQL` < 0.5 (ë³´ìˆ˜ì  í•™ìŠµ ì•ˆì •í™”)
- âœ… `Q-Value/Q1_Mean` ìˆ˜ë ´ (ë°œì‚°í•˜ì§€ ì•ŠìŒ)
- âœ… `GradNorm/Actor`, `GradNorm/Critic` < 10 (ì•ˆì •ì  í•™ìŠµ)

### Phase 2 (PPO-CVaR) ì„±ê³µ ê¸°ì¤€
- âœ… `Episode/Reward` > 0 (í‰ê· ì ìœ¼ë¡œ ìˆ˜ìµ)
- âœ… `CVaR/Value` < 0.05 (5% ë¦¬ìŠ¤í¬ ì œì•½ ë§Œì¡±)
- âœ… `Episode/TransactionCost` < 0.01 (1% ì´í•˜ ê±°ë˜ ë¹„ìš©)
- âœ… `Policy/KL_Divergence` < 0.1 (ì•ˆì •ì  policy ì—…ë°ì´íŠ¸)

---

## ğŸ“ ë¡œê·¸ íŒŒì¼ êµ¬ì¡°

```
checkpoints/
â””â”€â”€ run_20250115_143022/
    â”œâ”€â”€ phase1/
    â”‚   â”œâ”€â”€ tensorboard/          # TensorBoard ë¡œê·¸
    â”‚   â”‚   â””â”€â”€ events.out.tfevents.*
    â”‚   â”œâ”€â”€ cql_sac_step_50000.pt
    â”‚   â”œâ”€â”€ cql_sac_step_100000.pt
    â”‚   â””â”€â”€ cql_sac_final.pt
    â””â”€â”€ phase2/
        â”œâ”€â”€ tensorboard/          # TensorBoard ë¡œê·¸
        â”‚   â””â”€â”€ events.out.tfevents.*
        â”œâ”€â”€ ppo_cvar_step_20000.pt
        â””â”€â”€ ppo_cvar_final.pt
```

---

## ğŸŒ ì›ê²© ì„œë²„ ì ‘ì† (SSH í„°ë„ë§)

ì›ê²© ì„œë²„ì—ì„œ í•™ìŠµ ì¤‘ì¸ ê²½ìš°, ë¡œì»¬ ë¸Œë¼ìš°ì €ì—ì„œ TensorBoardë¥¼ ë³´ë ¤ë©´:

```bash
# ë¡œì»¬ ì»´í“¨í„°ì—ì„œ ì‹¤í–‰ (SSH í¬íŠ¸ í¬ì›Œë”©)
ssh -L 6006:localhost:6006 user@remote-server

# ê·¸ ë‹¤ìŒ ì›ê²© ì„œë²„ì—ì„œ TensorBoard ì‹¤í–‰
tensorboard --logdir checkpoints/run_20250115_143022/phase1/tensorboard

# ë¡œì»¬ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:6006 ì ‘ì†
```

---

## âš™ï¸ ê³ ê¸‰ ì˜µì…˜

### ë‹¤ë¥¸ í¬íŠ¸ ì‚¬ìš©
```bash
tensorboard --logdir checkpoints/run_20250115_143022/phase1/tensorboard \
  --port 6007 --bind_all
```

### ì—…ë°ì´íŠ¸ ì£¼ê¸° ì¡°ì •
```bash
# 30ì´ˆë§ˆë‹¤ ìƒˆë¡œê³ ì¹¨ (ê¸°ë³¸ê°’: 30ì´ˆ)
tensorboard --logdir ... --reload_interval 30
```

### ì—¬ëŸ¬ ì‹¤í—˜ ë””ë ‰í† ë¦¬ ë™ì‹œ ëª¨ë‹ˆí„°ë§
```bash
tensorboard --logdir checkpoints/ --port 6006 --bind_all
```
ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ì˜ tensorboard ë¡œê·¸ë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•©ë‹ˆë‹¤.

---

## ğŸ› ë¬¸ì œ í•´ê²°

### TensorBoardê°€ ì‹¤í–‰ë˜ì§€ ì•Šì„ ë•Œ
```bash
# TensorBoard ì„¤ì¹˜ í™•ì¸
pip install tensorboard

# í¬íŠ¸ê°€ ì´ë¯¸ ì‚¬ìš© ì¤‘ì¸ ê²½ìš°
lsof -ti:6006 | xargs kill -9  # ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
```

### ë¡œê·¸ê°€ ë³´ì´ì§€ ì•Šì„ ë•Œ
```bash
# ë¡œê·¸ ë””ë ‰í† ë¦¬ í™•ì¸
ls -la checkpoints/run_20250115_143022/phase1/tensorboard/

# events íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
# events.out.tfevents.* íŒŒì¼ì´ ìˆì–´ì•¼ í•¨
```

### ê·¸ë˜í”„ê°€ ì—…ë°ì´íŠ¸ë˜ì§€ ì•Šì„ ë•Œ
- ë¸Œë¼ìš°ì €ì—ì„œ **Ctrl+Shift+R** (ê°•ì œ ìƒˆë¡œê³ ì¹¨)
- TensorBoard ì¬ì‹œì‘

---

## ğŸ“š ì¶”ê°€ ìë£Œ

- [TensorBoard ê³µì‹ ë¬¸ì„œ](https://www.tensorflow.org/tensorboard)
- [TensorBoard GitHub](https://github.com/tensorflow/tensorboard)

---

**ì§ˆë¬¸ì´ë‚˜ ë¬¸ì œê°€ ìˆìœ¼ë©´ ì´ìŠˆë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”!**
